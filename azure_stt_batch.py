import os
import time
import datetime
import requests
import json
import tkinter as tk
from tkinter import filedialog

# azure-ai-speech SDK ëŒ€ì‹  azure-storage-blobë§Œ ì‚¬ìš©
from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions

# --- âš™ï¸ CONFIGURATION ---

# 1. Azure ìê²© ì¦ëª… (í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥)
SPEECH_KEY = os.environ.get("AZURE_SPEECH_KEY")
SPEECH_REGION = os.environ.get("AZURE_SPEECH_REGION")
AZURE_STORAGE_CONNECTION_STRING = os.environ.get("AZURE_STORAGE_CONNECTION_STRING")

# 2. Blob ì»¨í…Œì´ë„ˆ ì´ë¦„
BLOB_CONTAINER_NAME = "stt-audio-files" # ì´ ë¶€ë¶„ì€ ë³´ìŠ¤ì˜ ì»¨í…Œì´ë„ˆ ì´ë¦„ìœ¼ë¡œ ìœ ì§€

# 3. ì–¸ì–´ ë° API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
RECOGNITION_LANGUAGE = "ko-KR"
BASE_URL = f"https://{SPEECH_REGION}.api.cognitive.microsoft.com/speechtotext/v3.1/transcriptions"

# 4. SRT ìë§‰ ë¶„í•  ê¸°ì¤€
MAX_SECOND_PER_SEGMENT = 5.0
MAX_CHARS_PER_SEGMENT = 40

# --- HELPER FUNCTIONS ---
# (ì´ ë¶€ë¶„ì€ ì´ì „ ì½”ë“œì™€ ë™ì¼í•˜ë¯€ë¡œ, ë³€ê²½ ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤)

def to_srt_timestamp(total_seconds):
    total_seconds_float = float(total_seconds)
    hours, remainder = divmod(total_seconds_float, 3600)
    minutes, seconds = divmod(remainder, 60)
    milliseconds = int((seconds - int(seconds)) * 1000)
    return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}"

def upload_and_get_sas_url(blob_service_client, local_file_path):
    blob_name = os.path.basename(local_file_path)
    blob_client = blob_service_client.get_blob_client(container=BLOB_CONTAINER_NAME, blob=blob_name)
    
    print(f"  â¡ï¸ '{blob_name}' íŒŒì¼ì„ Azure Blob Storageì— ì—…ë¡œë“œ ì¤‘...")
    with open(local_file_path, "rb") as data:
        blob_client.upload_blob(data, overwrite=True)
    
    sas_token = generate_blob_sas(
        account_name=blob_client.account_name, container_name=blob_client.container_name, blob_name=blob_client.blob_name,
        account_key=blob_client.credential.account_key, permission=BlobSasPermissions(read=True),
        expiry=datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=24)
    )
    return f"https://{blob_client.account_name}.blob.core.windows.net/{blob_client.container_name}/{blob_client.blob_name}?{sas_token}"

def generate_srt_from_json_data(result_data, srt_output_path):
    print(f"  â¡ï¸ ë‹¤ìš´ë¡œë“œí•œ ê²°ê³¼ë¡œ SRT íŒŒì¼ ìƒì„± ì¤‘...")
    all_word_result = []
    for phrase in result_data.get('recognizedPhrases', []):
        best_phrase = phrase.get('nBest', [{}])[0]
        for word_info in best_phrase.get('words', []):
            all_word_result.append({
                'text': word_info['word'],
                'start_time': word_info['offsetInTicks'] / 10_000_000,
                'end_time': (word_info['offsetInTicks'] + word_info['durationInTicks']) / 10_000_000
            })

    if not all_word_result:
        print("  âš ï¸ ì¸ì‹ëœ ë‹¨ì–´ê°€ ì—†ì–´ SRT íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_word_result.sort(key=lambda x: x['start_time'])
    
    with open(srt_output_path, "w", encoding="utf-8") as srt_file:
        segment_index = 1
        current_segment_text, segment_start_time = "", all_word_result[0]['start_time']
        last_word_end_time = segment_start_time
        for i, word in enumerate(all_word_result):
            next_text = current_segment_text + (" " if current_segment_text else "") + word['text']
            segment_duration = word['end_time'] - segment_start_time
            if current_segment_text and (segment_duration > MAX_SECOND_PER_SEGMENT or len(next_text) > MAX_CHARS_PER_SEGMENT):
                srt_file.write(f"{segment_index}\n{to_srt_timestamp(segment_start_time)} --> {to_srt_timestamp(last_word_end_time)}\n{current_segment_text.strip()}\n\n")
                segment_index += 1
                current_segment_text, segment_start_time = word['text'], word['start_time']
            else:
                current_segment_text = next_text
            last_word_end_time = word['end_time']
        if current_segment_text:
            final_end_time = all_word_result[-1]['end_time']
            srt_file.write(f"{segment_index}\n{to_srt_timestamp(segment_start_time)} --> {to_srt_timestamp(final_end_time)}\n{current_segment_text.strip()}\n\n")

    print(f"  âœ… ì„±ê³µ! '{os.path.basename(srt_output_path)}' íŒŒì¼ ìƒì„± ì™„ë£Œ.")

# --- ğŸš€ MAIN EXECUTION ---

def main():
    # --- Tkinterë¥¼ ì´ìš©í•œ íŒŒì¼ ë° í´ë” ì„ íƒ ---
    root = tk.Tk()
    root.withdraw()

    print("íŒŒì¼ ì„ íƒ ëŒ€í™”ìƒìë¥¼ ì—½ë‹ˆë‹¤...")
    input_audio_files = filedialog.askopenfilenames(
        title="STT ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        filetypes=[("Audio Files", "*.wav *.mp3 *.ogg")]
    )
    if not input_audio_files:
        print("íŒŒì¼ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print("ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ì„ íƒ ëŒ€í™”ìƒìë¥¼ ì—½ë‹ˆë‹¤...")
    output_srt_folder = filedialog.askdirectory(
        title="SRT íŒŒì¼ì„ ì €ì¥í•  í´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    if not output_srt_folder:
        print("í´ë”ë¥¼ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # --- ë‚˜ë¨¸ì§€ ë¡œì§ ì‹¤í–‰ ---
    print("\n--- Azure Batch STT (REST API ë°©ì‹) í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ ---")

    if not all([SPEECH_KEY, SPEECH_REGION, AZURE_STORAGE_CONNECTION_STRING, BLOB_CONTAINER_NAME]):
        print("ì˜¤ë¥˜: Azure ìê²© ì¦ëª… ë˜ëŠ” ì»¨í…Œì´ë„ˆ ì´ë¦„ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    blob_service_client = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)
    headers = {'Ocp-Apim-Subscription-Key': SPEECH_KEY, 'Content-Type': 'application/json'}
    
    print(f"ì´ {len(input_audio_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n")

    for audio_file_path in input_audio_files:
        audio_file_name = os.path.basename(audio_file_path)
        print(f"--- ğŸµ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {audio_file_name} ---")
        try:
            sas_url = upload_and_get_sas_url(blob_service_client, audio_file_path)
            
            payload = {
                "contentUrls": [sas_url],
                "properties": {
                    "wordLevelTimestampsEnabled": True, "diarizationEnabled": False,
                },
                "locale": RECOGNITION_LANGUAGE, "displayName": f"Transcription for {audio_file_name}"
            }

            print("  â¡ï¸ Batch Transcription ì‘ì—…ì„ Azureì— ì œì¶œí•©ë‹ˆë‹¤ (POST ìš”ì²­)...")
            response = requests.post(BASE_URL, headers=headers, json=payload)
            response.raise_for_status()
            
            status_url = response.headers['Location']
            print(f"  âœ… ì‘ì—… ì œì¶œ ì„±ê³µ! (Status URL: {status_url})")

            print("  â¡ï¸ ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤...")
            while True:
                status_response = requests.get(status_url, headers=headers)
                status_response.raise_for_status()
                status_data = status_response.json()
                if status_data['status'] in ["Succeeded", "Failed"]:
                    break
                print(f"  ... í˜„ì¬ ìƒíƒœ: {status_data['status']} (30ì´ˆ í›„ ë‹¤ì‹œ í™•ì¸)")
                time.sleep(30)
            
            if status_data['status'] == "Succeeded":
                print(f"  âœ… ì‘ì—… ì„±ê³µ! ê²°ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
                files_url = status_data['links']['files']
                files_response = requests.get(files_url, headers=headers)
                files_response.raise_for_status()
                files_data = files_response.json()['values']
                
                result_url = next((f['links']['contentUrl'] for f in files_data if f['kind'] == 'Transcription'), None)
                if result_url:
                    result_response = requests.get(result_url)
                    result_response.raise_for_status()
                    srt_filename = os.path.splitext(audio_file_name)[0] + ".srt"
                    generate_srt_from_json_data(result_response.json(), os.path.join(output_srt_folder, srt_filename))
            else:
                print(f"  âŒ ì‘ì—… ì‹¤íŒ¨. Status: {status_data['status']}, Details: {status_data.get('properties', {}).get('error', {})}")

        except Exception as e:
            print(f"  âŒ '{audio_file_name}' ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        print(f"--- â¹ï¸ íŒŒì¼ ì²˜ë¦¬ ì¢…ë£Œ: {audio_file_name} ---\n")

    print("--- ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ---")

if __name__ == "__main__":
    main()